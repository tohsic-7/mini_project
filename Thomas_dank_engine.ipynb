{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 18\n",
    "IMG_RESIZE = 500\n",
    "IMG_CROP = 500\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "#import torch\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        print(\"privietsky\")\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=10, stride=2, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=5, stride=2, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=30, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        #self.pool3 = nn.MaxPool2d(kernel_size=4)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=30, out_channels=30, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(in_channels=30, out_channels=30, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=480, out_features=100)\n",
    "        self.fc_relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=10)\n",
    "        #self.fc_relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=10, out_features=num_classes)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        output = self.conv1(inp)\n",
    "        output = self.relu1(output)\n",
    "        output = self.pool1(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.pool2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        #output = self.pool3(output)\n",
    "        \n",
    "        output = self.conv4(output)\n",
    "        output = self.relu4(output)\n",
    "        \n",
    "        output = self.conv5(output)\n",
    "        output = self.relu5(output)\n",
    "        output = self.pool5(output)\n",
    "        \n",
    "        output = output.view(len(inp), 480)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.fc_relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.fc_relu(output)\n",
    "        output = self.fc3(output)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_classes = 2)\n",
    "#nn_model.init(num_classes = 2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = []\n",
    "validation_loss = []\n",
    "\n",
    "#training of network\n",
    "for epoch in range(epochs):\n",
    "    print('\\rEpoch: [{}/{}]'.format(epoch+1, epochs),end='')\n",
    "    epoch_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "    for batch_nr, (images, labels) in enumerate(train_loader):\n",
    "        # clear-the-gradients-of-all-optimized-variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "        predict = model.forward(images)\n",
    "        # calculate-the-batch-loss\n",
    "        loss = criterion(predict, labels)\n",
    "        epoch_loss +=loss\n",
    "        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
    "        loss.backward()\n",
    "         #perform-a-ingle-optimization-step (parameter-update)\n",
    "        optimizer.step() \n",
    "         #update-training-loss\n",
    "            \n",
    "    # Validation\n",
    "    for batch_nr, (images, labels) in enumerate(val_loader):\n",
    "        predict = model.forward(images)\n",
    "        val_loss = criterion(predict, labels)\n",
    "        epoch_validation_loss += val_loss\n",
    "\n",
    "    loss_data.append(epoch_loss/len(train_loader))\n",
    "    validation_loss.append(epoch_validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,epochs+1), loss_data,label='training')\n",
    "plt.plot(range(1,epochs+1),validation_loss, label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing \n",
    "correct = 0\n",
    "total = 0\n",
    "confusion = np.array([[0,0],[0,0]])\n",
    "for batch_nr, (images, labels) in enumerate(test_loader):\n",
    "    print('\\rBatch: [{}/{}]'.format(batch_nr+1, len(test_loader)),end='')\n",
    "    predict = model.forward(images)\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        preede = torch.argmax(predict[i])\n",
    "        is_correct = preede == labels[i]\n",
    "        \n",
    "        if(preede == labels[i]):\n",
    "            correct +=1\n",
    "        total += 1\n",
    "        if(labels[i] == 0):\n",
    "            if(is_correct):\n",
    "                confusion[0][0] += 1\n",
    "            else:\n",
    "                confusion[1][0] += 1\n",
    "        if(labels[i] == 1):\n",
    "            if(is_correct):\n",
    "                confusion[1][1] += 1\n",
    "            else:\n",
    "                confusion[0][1] += 1\n",
    "\n",
    "print(\"\\nCorrect : \", correct)\n",
    "print(\"Total : \", total)\n",
    "print(\"Accuracy : \" , correct/total*100 , \"%\")\n",
    "\n",
    "#plt.imshow(images[0][0])\n",
    "print(confusion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
