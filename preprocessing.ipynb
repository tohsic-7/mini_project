{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "progressive-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impressed-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(500),\n",
    "transforms.CenterCrop(500),\n",
    "transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder(\"./chest_xray./test/\", transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "dataset_val = datasets.ImageFolder(\"./chest_xray./val/\", transform=transform)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=10, shuffle=True)\n",
    "#dataset = torch.utils.data.ConcatDataset([dataset, dataset_rotation, dataset_jitter, dataset_affine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "humanitarian-agreement",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e7a6c4ecc687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m269\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m67\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvalidation_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[1;34m(dataset, lengths, generator)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;31m# Cannot verify that dataset is Sized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "training_set, validation_set = torch.utils.data.random_split(dataset, [269,67], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(training_set, batch_size=10, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=10, shuffle=True)\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "\n",
    "\n",
    "#plt.imshow(dataset[0][0][2], cmap='gray')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#subplot(r,c) provide the no. of rows and columns\n",
    "f, axarr = plt.subplots(3,1) \n",
    "\n",
    "# use the created array to output your multiple images. In this case I have stacked 4 images vertically\n",
    "axarr[0].imshow(dataset[300][0][0])\n",
    "axarr[1].imshow(dataset[300][0][1])\n",
    "axarr[2].imshow(dataset[300][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nutritional-tokyo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x261b69eaeb8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "#subplot(r,c) provide the no. of rows and columns\n",
    "f, axarr = plt.subplots(3,1) \n",
    "\n",
    "# use the created array to output your multiple images. In this case I have stacked 4 images vertically\n",
    "axarr[0].imshow(dataset[300][0][0])\n",
    "axarr[1].imshow(dataset[300][0][1])\n",
    "axarr[2].imshow(dataset[300][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "horizontal-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "#import torch\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        print(\"priviet\")\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=30, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=4)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=1470, out_features=num_classes)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        output = self.conv1(inp)\n",
    "        output = self.relu(output)\n",
    " \n",
    "        output = self.pool(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "\n",
    "        output = self.pool2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        output = self.pool3(output)\n",
    "        \n",
    "\n",
    "        output = output.view(len(inp), 1470)\n",
    "\n",
    "        output = self.fc1(output)\n",
    "\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handled-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priviet\n"
     ]
    }
   ],
   "source": [
    "model = Model(num_classes = 2)\n",
    "#model = model.cuda()\n",
    "#nn_model.init(num_classes = 2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/100]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss_data = []\n",
    "validation_loss = []\n",
    "\n",
    "#training of network\n",
    "for epoch in range(epochs):\n",
    "    print('\\rEpoch: [{}/{}]'.format(epoch+1, epochs),end='')\n",
    "    epoch_loss =0\n",
    "    for batch_nr, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        # clear-the-gradients-of-all-optimized-variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "        predict = model.forward(images)\n",
    "        # calculate-the-batch-loss\n",
    "        loss = criterion(predict, labels)\n",
    "        epoch_loss +=loss\n",
    "        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
    "        loss.backward()\n",
    "         #perform-a-ingle-optimization-step (parameter-update)\n",
    "        optimizer.step()\n",
    "         #update-training-loss\n",
    "    loss_data.append(epoch_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "planned-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: [0/0.2]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-15caeeb93fea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_nr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\rEpoch: [{}/{}]'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_nr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-d5885501ebd4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "correct = 0\n",
    "total = 0\n",
    "confusion = np.array([[0,0],[0,0]])\n",
    "for batch_nr, (images, labels) in enumerate(val_loader):\n",
    "    print('\\rEpoch: [{}/{}]'.format(batch_nr, len(val_loader)),end='')\n",
    "    predict = model.forward(images)\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        preede = torch.argmax(predict[i])\n",
    "        is_correct = preede == labels[i]\n",
    "        if(preede == labels[i]):\n",
    "            correct +=1\n",
    "        total += 1\n",
    "        if(labels[i] == 0):\n",
    "            if(is_correct):\n",
    "                confusion[0][0] += 1\n",
    "            else:\n",
    "                confusion[1][0] += 1\n",
    "        if(labels[i] == 1):\n",
    "            if(is_correct):\n",
    "                confusion[1][1] += 1\n",
    "            else:\n",
    "                confusion[0][1] += 1\n",
    "\n",
    "print(\"Correct : \", correct)\n",
    "print(\"Total : \", total)\n",
    "print(\"Accuracy : \" , correct/total*100 , \"%\")\n",
    "\n",
    "#plt.imshow(images[0][0])\n",
    "print(confusion)\n",
    "\n",
    "plt.plot(range(1,epochs+1), loss_data,label='training')\n",
    "#plt.plot(range(1,epochs+1),total_validation_loss, label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "varying-storm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priviet\n",
      "cuda:0   conv1.weight\n",
      "cuda:0   conv1.bias\n",
      "cuda:0   conv2.weight\n",
      "cuda:0   conv2.bias\n",
      "cuda:0   conv3.weight\n",
      "cuda:0   conv3.bias\n",
      "cuda:0   fc1.weight\n",
      "cuda:0   fc1.bias\n"
     ]
    }
   ],
   "source": [
    "model_gpu = Model(num_classes = 2)\n",
    "model_gpu = model_gpu.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_gpu.parameters(),lr = 0.0001)\n",
    "for n, p in model_gpu.named_parameters():\n",
    "    print(p.device, ' ', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collective-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100/100]"
     ]
    }
   ],
   "source": [
    "loss_data = []\n",
    "\n",
    "\n",
    "#training of network\n",
    "for epoch in range(epochs):\n",
    "    print('\\rEpoch: [{}/{}]'.format(epoch+1, epochs),end='')\n",
    "    epoch_loss =0\n",
    "    for batch_nr, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        # clear-the-gradients-of-all-optimized-variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n",
    "        predict = model_gpu.forward(images)\n",
    "        # calculate-the-batch-loss\n",
    "        loss = criterion(predict, labels)\n",
    "        epoch_loss +=loss\n",
    "        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n",
    "        loss.backward()\n",
    "         #perform-a-ingle-optimization-step (parameter-update)\n",
    "        optimizer.step()\n",
    "         #update-training-loss\n",
    "    loss_data.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "technological-definition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch: [1/2]\r",
      "Batch: [2/2]\n",
      "Correct :  12\n",
      "Total :  16\n",
      "Accuracy :  75.0 %\n",
      "[[6 2]\n",
      " [2 6]]\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "validation_loss = []\n",
    "batch = []\n",
    "correct = 0\n",
    "total = 0\n",
    "confusion = np.array([[0,0],[0,0]])\n",
    "for batch_nr, (images, labels) in enumerate(val_loader):\n",
    "    print('\\rBatch: [{}/{}]'.format(batch_nr+1, len(val_loader)),end='')\n",
    "    images = images.to('cuda')\n",
    "    labels = labels.to('cuda')\n",
    "    predict = model_gpu.forward(images)\n",
    "    loss = criterion(predict, labels)\n",
    "    validation_loss.append(loss)\n",
    "    batch.append(batch_nr)\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        preede = torch.argmax(predict[i])\n",
    "        is_correct = preede == labels[i]\n",
    "        if(preede == labels[i]):\n",
    "            correct +=1\n",
    "        total += 1\n",
    "        if(labels[i] == 0):\n",
    "            if(is_correct):\n",
    "                confusion[0][0] += 1\n",
    "            else:\n",
    "                confusion[1][0] += 1\n",
    "        if(labels[i] == 1):\n",
    "            if(is_correct):\n",
    "                confusion[1][1] += 1\n",
    "            else:\n",
    "                confusion[0][1] += 1\n",
    "\n",
    "print(\"\\nCorrect : \", correct)\n",
    "print(\"Total : \", total)\n",
    "print(\"Accuracy : \" , correct/total*100 , \"%\")\n",
    "\n",
    "#plt.imshow(images[0][0])\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "promotional-occupation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-560781a9de09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2840\u001b[0m     return gca().plot(\n\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2842\u001b[1;33m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,epochs+1), loss_data,label='training')\n",
    "plt.plot(batch,validation_loss, label='validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-pleasure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
